# 시간축기반 데이터 모델링

아래 그림 처럼 초 단위로 데이터를 모두 개별 도큐먼트로 컬렉션에 쌓아두게 되면 Index Size 가 급격하게 증가한다. 그리고, 분 단위로 데이터를 묶고 그 안에 초 단위 데이터를 모아두면 Index Size가 완만하게 증가한다. 데이터를 무분별하게 방만하게 그대로 쌓아두는 것보다 효율적으로 저장하는 것도 좋은 설계인 것 같다는 생각이 든다. <br>

이렇게 설계를 해두면 나중에 관리비용도 줄어들게 된다.<br>

![이미지](https://webassets.mongodb.com/_com_assets/cms/image2-t7gc19lv4c.png)

그림 출처 :  https://webassets.mongodb.com/_com_assets/cms/image2-t7gc19lv4c.png <br>

분단위(PerMinute)로 데이터를 저장한다는 것의 의미는 아래와 같은 방식의 모델로 저장한다는 것을 의미한다.<br>

> 도큐먼트 하나에 0초, 1초, ~ 60초 까지의 모든 초를 하나의 필드에 객체로 저장하고 있는 모델<br>

예를 들면 아래와 같은 모양이다.<br>

<br>

```javascript
{
    "_id" : ObjectId("5b5279d1e303d394db6ea0f8"), 
    "p" : {
        "0" : 56.56,
        "1" : 56.56,
        "2" : 56.58,
        …
        "59" : 57.02
    },
   "symbol" : "MDB",
   "d" : ISODate("2018-06-30T00:00:00Z")
}
```

위와 같은 모델과 다른 모델들과의 성능측정을 해본 것에 대한 자세한 내용은 아래에서부터 정리할 예정이다.<br>

<br>

## 목차

- [참고자료](#참고자료)<br>
- [예) 시간축 도큐먼트 모델링의 종류들](#예-시간축-도큐먼트-모델링의-종류들)<br>
  - [시나리오 1. 초 단위 도큐먼트 모델링](#시나리오-1-초-단위-도큐먼트-모델링)<br>
  - [시나리오 2. 분 단위 버킷 모델링](#시나리오-2-분-단위-버킷-모델링)<br>
  - [시나리오 3. 크기 기반 버킷화](#시나리오-3-크기-기반-버킷화)<br>
- [스키마 설계 효과 비교](#스키마-설계-효과-비교)<br>
  - [Data Storage 측면](#Data-Storage-측면)<br>
    - [Document Size](#Document-Size)<br>
    - [Collection Size](#Collection-Size)<br>
  - [메모리 활용도에 미치는 영향](#메모리-활용도에-미치는-영향)<br>
    - [수평적 스케일링](#수평적-스케일링)<br>

<br>

## 참고자료

[github - RWaltersMA/StockPriceGenerator](https://github.com/RWaltersMA/StockPriceGenerator)<br>

- MongoDB 내에 가짜 주식 데이터를 생성하는 툴이다.<br>
- 아래 블로그 글의 저자의 github 인데, 주식 데이터를 생성하는 python 코드 역시도 제공을 해주고 있다.<br>

<br>

**www.mongodb.com/blog**<br>

- [Time Series Data and MongoDB : Part1 - An Introduction](https://www.mongodb.com/blog/post/time-series-data-and-mongodb-part-1-introduction)<br>
- [Time Series Data and MongoDB : Part2 - Schema Design Best Practices](https://www.mongodb.com/blog/post/time-series-data-and-mongodb-part-2-schema-design-best-practices)<br>
- [Time Series Data and MongoDB : Part3 - Querying, Analyzing, and Presenting Time Series Data](https://www.mongodb.com/blog/post/time-series-data-and-mongodb-part-3--querying-analyzing-and-presenting-timeseries-data)<br>

<br>

**Time-Series Data in MongoDB**<br>

- [https://techblog.dac.digital/time-series-data-in-mongodb-380f6cf36494](https://techblog.dac.digital/time-series-data-in-mongodb-380f6cf36494) <br>
- 도큐먼트 하나에 모두 모아놓는 방식. Embeded 참조 방식<br>

<br>

위의 자료들 중 가장 읽어볼 만한 자료는 아래와 같았다.<br>

- [Time Series Data and MongoDB : Part2 - Schema Design Best Practices](https://www.mongodb.com/blog/post/time-series-data-and-mongodb-part-2-schema-design-best-practices)<br>
- [Time Series Data and MongoDB : Part3 - Querying, Analyzing, and Presenting Time Series Data](https://www.mongodb.com/blog/post/time-series-data-and-mongodb-part-3--querying-analyzing-and-presenting-timeseries-data)<br>

<br>

## 예) 시간축 도큐먼트 모델링의 종류들

>[Time Series Data and MongoDB : Part2 - Schema Design Best Practices](https://www.mongodb.com/blog/post/time-series-data-and-mongodb-part-2-schema-design-best-practices) 에서는 이것을 각각 <br>
>
>- Scenario 1 : One Document per data point<br>
>- Scenario 2 : Time-based bucketing of one document per minute<br>
>- Scenario 3 : Size-based bucketing<br>
>
>이렇게 설명하고 있는데, 각각을 호칭할 방법이 애매해서, 일단은 아래와 같은 한국어로 명칭을 정해서 정리해두기로 결정했다.<br>
>
>- Scenario 1: 초 단위 도큐먼트 모델링<br>
>- Scenario 2 : 분 단위 버킷 모델링<br>
>- Scenario 3 : 크기 기반 버킷화<br> 
>
>단일 시간축 데이터, 초 단위 버킷 도큐먼트, 크기 기반 버킷화 라고 이름을 지어서 정리하기로 해두었다. 나중에 이름을 변경하거나, 목차의 이름을 수정할 예정이다.<br>

<br>

### 시나리오 1. 초 단위 도큐먼트 모델링

도큐먼트 각각이 고유시간축을 갖게 하는 경우의 모델이다. 누구나 처음에 떠올리기 쉬운 모델이다.<br>

```javascript
{
  "_id" : ObjectId("5b4690e047f49a04be523cbd"),
  "p" : 56.56,
  "symbol" : "MDB",
  "d" : ISODate("2018-06-30T00:00:01Z")
},
{
  "_id" : ObjectId("5b4690e047f49a04be523cbe"),
  "p" : 56.58,
  "symbol" : "MDB",
  "d" : ISODate("2018-06-30T00:00:02Z")
},
...
```

<br>

### 시나리오 2. 분 단위 버킷 모델링

아래의 예는 각 분에 대한 `1초` , `2초` , ... `59초` , `00초`  를 1분, 2분, 등 각 분 내에 `p`  라는 서브도큐먼트 필드에서 모두 관리하도록 하는 예제이다. 이렇게 하면, 각 분마다 `0초` ,`1초` ~ `59` 초는 항상 있는 것이 자명한 사실이기 때문에 각 분 데이터에서 초 데이터를 관리하면 된다. <br>

```javascript
{
    "_id" : ObjectId("5b5279d1e303d394db6ea0f8"), 
    "p" : {
        "0" : 56.56,
        "1" : 56.56,
        "2" : 56.58,
        …
        "59" : 57.02
    },
   "symbol" : "MDB",
   "d" : ISODate("2018-06-30T00:00:00Z")
},
   {
    "_id" : ObjectId("5b5279d1e303d394db6ea134"), 
    "p" : {
        "0" : 69.47,
        "1" : 69.47,
        "2" : 68.46,
        ...
       "59" : 69.45
    },
    "symbol" : "TSLA",
    "d" : ISODate("2018-06-30T00:01:00Z")
},
...

```

<br>

하지만, 단점으로 생각해볼만한 요소는 아래와 같았었다.<br>

- 초별로 데이터를 저장하는 경우는 그렇게 많지 않다.<br>
  - 이 경우는 위의 예제를 응용해서 각 시간에 대한 데이터를 p라는 객체에 `0분` , `1분` , ... `59분`  등으로 지정해 저장하는 경우도 생각해볼수 있을 것 같다.<br>
- 초마다 데이터가 제대로 들어올지도 장담할 수 없을 수 있다는 점이 단점인 것 같다.<br>
  - null 처리 또는 nvl 처리를 잘 해둔다는 가정을 한다면 유효할 것 같다.<br>

<br>

### 시나리오 3. 크기 기반 버킷화

[Time Series Data and MongoDB - Part2](https://www.mongodb.com/blog/post/time-series-data-and-mongodb-part-2-schema-design-best-practices) 에서는 조금 실제 사용분야를 꽤 디테일하게 묘사를 해서, 읽을때 힘들 수 있는 사람들도 있을 수 있을 것 같다는 생각이 들었다. 오늘 이 글에서는 최대한 요약만을 해서 정리해보려 한다.<br>

우리가 IoT 서비스를 제공하고 있다고 해보자. IoT 분야에서 시간축 기반의 애플리케이션을 운영할 때, 센서 데이터 같은 데이터들은 데이터가 불규칙하게 생성된다. 이렇게 불규칙하게 데이터가 생성될 경우 시나리오 2의 시간축 기반 버킷 모델은 좋은 선택이 될 수 없다.<br>

이런 경우에 대비해서 대안으로 제공되는 것이 size-based 버킷팅 이다. size-based 버킷팅은 발생되는 센서 이벤트 몇 개의 묶음에 대해서 하나의 도큐먼트가 존재하도록 하는 방식이다. 예를 들면 이런 경우를 들 수 있다.<br> 

- 센서 데이터를 저장하기 위해 컬렉션을 생성하려고 하고, 도큐먼트 하나에 200개의 이벤트 만을 저장하기로 제한을 두는 경우<br>
- 센서데이터를 저장하기 위해 컬렉션을 생성하려고 하고, 도큐먼트 하나에 저장되는 값을 하루 중 가장 먼저 발생하는 이벤트를 저장하도록 제한하도록 하는 경우<br>

**예제**<br>

```javascript
{
    _id: ObjectId(),
    deviceid: 1234,
    sensorid: 3,
    nsamples: 5,
    day: ISODate("2018-08-29"),
    first:1535530412,
    last: 1535530432,
    samples : [
       { val: 50, time: 1535530412},
       { val: 55, time : 1535530415},
       { val: 56, time: 1535530420},
       { val: 55, time : 1535530430}, 
       { val: 56, time: 1535530432}
   ]
}
```

위 컬렉션의 구조에서  nsamples 라는 필드를 보면 도큐먼트 하나에 5개 까지만 데이터를 저장할 수 있도록 제한을 두고 있다.<br>

이렇게 한 도큐먼트 내에서 insert 할 수 있는 서브 데이터의 갯수를 제한하도록 지정하는 것은 언뜻 보기엔 어려워 보일 수도 있지만 아래와 같이 upsert 구문을 통해 간편하게 적용가능하다.<br>

```javascript
sample = {val: 59, time: 1535530450}
day = ISODate("2018-08-29")
db.iot.updateOne({deviceid: 1234, sensorid: 3, nsamples: {$lt: 200}, day: day},
                 {
                          $push: { samples: sample},
                          $min: { first: sample.time},
                          $max: { last: sample.time},
                          $inc: { nsamples: 1} 
                  }, 
                  { upsert: true } )

```

사이즈 기반 버킷팅의 가장 최적의 인덱스는 `{deviceid: 1, sensorid:1, day: 1, nsamples:1}` 일때 가장 최적이다. 데이터의 업에이트할때 날짜가 정확히 일치하기 때문에 효율적인 경우이다.<br>

<br>

## 스키마 설계 효과 비교

[Time Series Data and MongoDB : Part2 - Schema Design Best Practices](https://www.mongodb.com/blog/post/time-series-data-and-mongodb-part-2-schema-design-best-practices) 에서는 시나리오1의 도큐먼트와 시나리오2의 도큐먼트 모델을 4주 정도의 데이터를 쌓아본후 측정한 결과를 설명하고 있다. 아래는 그 내용들을 요약한 내용이다.<br>

<br>

### Data Storage 측면

> - 시나리오 1 : 초 단위 도큐먼트 모델링<br>
>
> - 시나리오 2 : 분 단위 버킷 모델링<br>

<br>

#### Document Size

초단위에 대한 각각의 도큐먼트들을 저장하는 시나리오1 의 모델은 처음에 떠올리기 쉬운 모델이다. 데이터 포인트 하나당 하나의 문서를 사용하고 있다.<br>

아래에서 보듯이 PerSecond 의 도큐먼트들의 갯수가 Perminute 의 도큐먼트의 갯수보다 압도적으로 많다. 데이터의 갯수가 기하급수적으로 많아진다는 것은 클라우드 센터를 사용하고 있다면 관리비용이 증가한다는 것을 의미한다. 1초 단위의 데이터를 수집하는 것은 분명 데이터가 많이 쌓인다. 또한 도큐먼트의 갯수가 늘어난다는 것은 그만큼 인덱싱 성능이 느려질 경우에 대해 복제 또는 샤딩 등의 작업을 해주어야 할 수 있다는 것을 의미한다.<br>

1분 단위 내에는 60개의 초가 들어가는 것은 자명한 사실이기에, 이런 경우에 대해서는 분 단위 버킷 모델링을 도입해서 도큐먼트의 갯수를 축소시키는 것도 나쁜 선택은 아닌 것 같다.<br>

![이미지](https://webassets.mongodb.com/_com_assets/cms/image1-esn30j6wcb.png)

이미지 출처 : https://webassets.mongodb.com/_com_assets/cms/image1-esn30j6wcb.png<br>

<br>

#### Collection Size

**디스크 스토리지 비교**<br>

`초 단위 모델링` : Disk Storage 는 7일 째에는 29.83MB 이다. 그리고 28일 째에는 190.64MB 가 되었다.<br>

`분 단위 모델링` : Disk Storage 는 7일 째에는 8.1MB 이다. 그리고 28일 째에는 52.71MB 가 되었다.<br>

<br>

`초 단위 모델링` : Data Size 는 7일 째에는 96.84MB 이다. 그리고 28일 째에는 605.42MB 가 되었다.<br>

`분 단위 모델링` : Data Size 는 7일 째에는 20.46MB 이다. 그리고 28일 째에는 127.94MB 가 되었다.<br>

<br>

![이미지](https://webassets.mongodb.com/_com_assets/cms/image3-sw744kq908.png)

이미지 출처 : https://webassets.mongodb.com/_com_assets/cms/image3-sw744kq908.png<br>

<br>

### 메모리 활용도에 미치는 영향

도큐먼트의 갯수가 많아지게 되는 것은 데이터 스토리지 소비량, 인덱스 사이즈 모두가 커지게 된다. 인덱스는 보통 각 컬렉션에 생성되고, 날짜,심볼 필드들에 적용된다. 최근 시간축을 위한 데이터베이스로 자리잡고 있는 key-value 데이터베이스들과는 다르게 몽고DB는 Secondary Index를 제공한다. Secondary Index는 데이터에 유연하게 액세스할 수 있도록 해주고, 애플리케이션의 쿼리 성능을 최적화할 수 있도록 해준다.<br>

![이미지](https://webassets.mongodb.com/_com_assets/cms/image2-t7gc19lv4c.png)

이미지 출처 : https://webassets.mongodb.com/_com_assets/cms/image2-t7gc19lv4c.png <br>

위 그림은 초단위 모델과 분단위 버킷 모델의 시간의 흐름에 따른 인덱스 사이즈를 비교하고 있다.<br>

육안으로 보기에도 초단위 모델이 기하급수적으로 인덱스 사이즈가 증가하는 것을 확인할 수 있다.<br>

`초 단위 모델링` : Index Size 는 7일 째에는 25.37MB 이다. 그리고 28일 째에는 103.03MB 가 되었다.<br>

`분 단위 모델링` : Index Size 는 7일 째에는 0.4MB 이다. 그리고 28일 째에는 1.86MB 가 되었다.<br>

<br>

인덱스의 사이즈를 줄이는 방식으로 Index Prefix Compression 과 같은 몇 가지 최적화 기능이 있다. 이렇게 Index Prefix Compression 같은 최적화 방식에도 불구하고 인덱스 크기가 급격하게 증가하는 것을 막기 위해서는 적절한 스키마 설계가 중요하다.<br>

<br>

### 수평적 스케일링

샤딩에 대해서 언급해주고 있다. 정리필요요요요요<br>

<br>

## 오래된 데이터를 관리하는 방식들

### Pre-aggregation

### Offline archival strategies

### Online archival strategies