# 레플리카 세트, 복제세트

몽고DB에서의 레플리카 세트의 개념에 대해 정리해보려 한다. 실무에서 상용 바로 아래 단계의 테스트 용도의 개발용 몽고 DB를 최소한도의 사양으로 스탠드얼론 -> 레플리카 세트 구축 -> 샤드 클러스터 구축 의 순서로 구축해본 경험이 있었었다. 하지만, 레플리카 세트, 샤드 클러스터에 대한 개념적인 이해도가 떨어진다는 생각이 자주 들었었다. 이런 이유로 책을 찾아봐야 겠다는 생각을 하게 되었고, 이번 개념 정리 글을 시작하게 되었다.    

  

DB 서버를 운영하다보면 아래와 같은 예상치 못한 상황이 발생하는 경우가 있다. 이런 경우 복제를 통해 이중화가 되어 있다면, 예기치 못한 장애에 대해 미리 대비가 가능하다는 장점이 있다.  

- 애플리케이션과 데이터베이스 사이의 네트워크 단절
- 데이터베이스 서버의 하드디스크 장애

  

**용어통칭 : 레플리카 세트 vs 복제 세트**  

보통의 대부분의 책에서는 복제 세트 이렇게 명칭하는 경우가 많은데, 복제 세트라는 말이 아무리해도 내 머릿속에는 들어오지 않아서 이 문서에서는 레플리카 세트 라는 용어로 통칭할 예정이다.(처음 배울때 레플리카 세트라고 배워서 이렇게 주입이 되어서 그런 것 같다.)  

​    

## 목차

- [참고자료](#참고자료)
- [복제 (Replication, 레플리케이션)](#복제 (Replication, 레플리케이션))
- [저널링의 필요성](#저널링의 필요성)
- [복제가 도움이 되지 않는 경우들](#복제가 도움이 되지 않는 경우들)
- [오피로그 동작방식](#오피로그 동작방식)
- [레플리카 세트의 장점](#레플리카 세트의 장점)
- [레플리카 세트에서의 커밋과 롤백](#레플리카 세트에서의 커밋과 롤백)
- [레플리카 세트에서의 하트비트,장애복구](#레플리카 세트에서의 하트비트,장애복구)
- [레플리카 세트에서의 프라이머리 구성원](#레플리카 세트에서의 프라이머리 구성원)
- [레플리카 세트에서의 세컨더리 구성원](#레플리카 세트에서의 세컨더리 구성원)
- [레플리카 세트에서의 아비터 구성원](#레플리카 세트에서의 아비터 구성원)
- [레플리카 세트의 선거 방식](#레플리카 세트의 선거 방식)

  

## 참고자료

- [몽고디비 인 액션](http://www.yes24.com/Product/Goods/60659843)
  - 내용 요약할 때 조금 힘들었다. 횡설수설 스타일이어서 개념을 요약하는데에 어려움을 꽤나 겪은편이다.
- 부교재
  - [맛잇는 MongoDB](http://www.yes24.com/Product/Goods/85011885)



## 복제 (Replication, 레플리케이션)

흔히 Replica, 레플리카 라고 부르는 복제는 여러 개의 MongoDB 서버(노드)에 데이터를 분산해서 저장하고 관리하는 것을 의미한다. 몽고 DB에서는 아래의 두가지 방식으로 복제를 할 수 있다.  

- 마스터-슬레이브(Master-Slave) 방식
  - 조금 오래된 방식의 복제방식이다. 몽고 DB에서는 MongoDB v3.0 에서 사용할 수 있는 방식이다.
- 복제세트(Replica Set) 방식
  - 마스터 슬레이브와 레플리카 세트는 같은 복제 메커니즘을 사용한다. 
  - 복제 세트는 여기에 더해 자동 장애 조치를 보장한다.

  

복제는 중복성, 장애복구, 유지, 로드밸런싱(load balancing)기능을 제공해준다.

- 중복성
  - 복제는 중복성을 제공해준다. 
  - 복제된 노드는 프라이머리 노드와 동기화된 상태를 유지한다.
  - 이렇게 중복성을 갖는 복제된 노드는 누군가 우발적으로 컬렉션을 삭제하거나 데이터베이스를 손상시키는 경우의 대비책이 된다.
  - 복제된 노드는 프라이머리 노드와 지리적으로 분산시켜서, 추가적인 안전 장치로 작용하게끔 할 수 있다. (자연재해, 정전 등의 사고에 대비) 이렇게 중복성을 갖는 복제된 노드는 예기치 못한 사고에 대한 대비책이 될 수 있다.
- 장애복구
  - 몽고 DB는 비상시에 중복 노드로 전환할 수 있도록 장애복구 기능을 제공해준다.
- 유지 - 데이터베이스 관리 작업의 단순화 
  - 복제는 유지보수성을 간편하게 해준다. 유지보수를 간편하게 해주는 대표적인 예를 들어보면 아래와 같다.
  - 프라이머리 노드에서의 다운타임을 미연에 방지하기 위해 백업을 세컨더리 노드에서 수행하는 경우
  - 대용량의 인덱스를 구축할 때 리소스가 많이 필요한데, 이때 세컨더리 노드에 먼저 구축한 후에 기존 프라이머리와 세컨더리 노드를 교체하여, 다시 세컨더리가 된 이전의 프라이머리 노드에 인덱스를 구축하는 경우
- 로드밸런싱 (load balancing)
  - 복제 기능은 레플리카 셋 내부 구성원간의 로드밸런스 기능을 제공해준다.



## 저널링의 필요성

데이터 손실을 대비하지 않는 한 실제 **운영환경의 MongoDB 인스턴스를 복제 및 저널링으로 실행하는 것이 좋다**(만약 그렇지 않다면, 이것은 부실한 배포관행으로 간주되어야 한다.). 저널링을 사용하면 저널을 재실행해서 장애가 발생한 노드를 다시 복구할 수 있기 때문에 복구가 더 빨라진다. 저널링을 수행하는 것이 다른 복제본으로부터 재동기화해서 장애를 복구하는 것보다 빠르다는 것이 장점이다. 물론 저널링이 적용된 경우 역시도 복제를 적용하는 것 역시 권장되는 사항이다.    

MongoDB의 데이터 파일은 저널링이 사용되지 않았을 때에 예기치 않은 셧다운이 발생했을 경우 손상될 가능성이 있다. (저널링이 설정되어 있는 데이터 파일은 손상되지 않는다.) 이렇게 데이터 파일에 저널링이 적용되지 않았을 경우 역시 대비해서 복제가 항상 수행되어야 한다.  

  

**참고) 백업**  

백업을 하는 선택은 데이터가 상당히 큰 경우로 인해 실용적이지 않은 선택이 될 경우가 많지만, 일반적으로 백업은 레플리카 세트 내의 구성원에 대해 실행하는 경우이더라도, 신중하게 검토되어야 하는 사항이다. 백업은 데이터 손실, 데이터 손상과 같은 논리적인 오류가 발생한 경우를 대비해 존재하는 기능이라고 [책](http://www.yes24.com/Product/Goods/60659843)에서는 강조하고 있다.



## 복제가 도움이 되지 않는 경우들

**읽기에 대한 쓰기 비율이 50%를 초과하는 경우**  

50%는 약간은 주관적인 견해가 섞인 값이다. 하지만, 이 비율부터 시작하면 어느 정도 타당해진다고 한다.  

책에서는 다소 횡설 수설하게 설명하고 있는 관계로 다소 혼동했는데, 요약해보면 이런 뜻이다.

> 세컨더리 노드에 쓰기 작업이 이미 세컨더리에서 이미 수행중인 읽기 비율의 50% 를 초과할 경우 다소 위험할 수 있다. (저자의 주관적인 견해).  
>
> 쓰기 연산이 높아진 세컨더리 노드에 읽기 요청을 하게 될 경우 아래와 같은 단점이 있다.
>
> - 복제 프로세스를 지연시키게 된다. (프라이머리에 대한 쓰기 연산을 세컨더리 노드에도 적용하는 연산을 지연시키게 된다.)
> - 읽기 효율(throughput)이 나빠진다.
>
> 이렇게 쓰기 비율이 읽기비율의 50% 이상을 넘어가게 되는 경우를 프라이머리 노드에 대한 쓰기 연산이 세컨더리 노드에 적용하기 위한 쓰기 연산을 예로 들었다. (급작스러운 쓰기 트래픽 증가 등을 이야기하려고 한 듯 하다.)



**애플리케이션에서 일관성이 요구되는 읽기가 필요한 경우**  

세컨더리 노드는 비동기적으로 복제를 수행한다. 따라서 프라이머리 노드에서 수행된 마지막 쓰기를 반영하지 못할 수도 있다. 따라서 프라이머리 노드에서 수행된 마지막 쓰기를 반영하지 못할 수도 있다.  

예를 들면, 수강신청을 하거나, 인기 아이돌의 티켓을 예매하는 프로그램 등에서는 복제가 적용된 시스템 보다는 트랜잭션의 격리성이 어느 정도 보장된 환경에서 해야 하지 않을까하는 개인적인 의견이 들었다.  

  

할당된 하드웨어가 주어진 일을 처리할 수 없는 경우

작업 데이터가 가용 램보다 많을 경우 세컨더리 노드로 읽기 요청을 하게되는데, 기대했던 만큼의 성능향상이 이뤄지지 않을 수도 있다. 이런 시나리오에서 성능은 디스크가 처리할 수 있는 초당 입출력 연산 횟수 (IOPS) 에 따라 제한된다.  

복제본을 읽으면 IOPS가 증가하지만 IOPS가 100에서 200으로 늘어나도 성능문제가 해결되지 않는 경우가 있다. (물리적 성능의 한계보다 트래픽이 더 높을 경우)  

쓰기가 동시에 발생하고 그 수의 일부를 소비하는 경우인데, 이 경우 샤딩(sharding)이 더 나은 옵션이 될 수 있다.  

  

## 오피로그 동작방식

레플리카 세트는 오피로그(oplog), 하트비트(heartbeat)매커니즘에 의존한다.  

- 오피로그(oplog) 
  - 오피로그를 이용해 데이터 복제가 가능하다.
- 하트비트(heartbeat)
  - 시스템의 건강상태를 체크하는 몽고DB 내의 기능이다.



**오피로그**  

MongoDB 복제기능의 중심에는 오피로그가 있다. 오피로그의 특징은 아래와 같다.  

- 오피로그는 local 이라는 데이터베이스 내에 존재한다.
- 캡드(capped) 컬렉션이다.
- 데이터에 대한 모든 수정사항을 기록한다.



클라이언트가 프라이머리에 쓰기를 할 때마다 해당 쓰기 작업을 세컨더리에서 재생하기 위한 충분한 정보가 프라이머리 노드의 오피로그에 자동으로 추가된다. 쓰기 데이터가 세컨더리 노드에도 복제되고 나면 쓰기 정보가 그 세컨더리 노드의 오피로그에도 기록된다. 각 오피로그 항목은 BSON 타임스탬프로 인식한다. 이 타임스탬프를 기반으로 최신버전을 구분해서 추적한다.  

  

**세컨더리의 오피로그 동작방식**    

세컨더리는 오피로그 내의 위치에 대한 정보를 계속해서 유지한다. 이것이 가능한 것은 세컨더리 역시 오피로그를 가지고 있기 때문이다. (마스터 - 슬레이브 복제방식에 비해 발전된 방식이다.)  

세컨더리는 프라이머리의 오피로그로부터 새로 추가된 항목을 즉각 적용하기 위해 롱 폴링(long polling)을 사용한다. 롱 폴링은 세컨더리가 프라이머리에 장기간 요청을 보내는 것을 의미한다. 프라이머리가 수정사항을 수신하면 즉시 대기 요청에 응답한다.  

만약 네트워크 장애나 세컨더리 노드에 대한 유지보수 작업 때문에 최신 데이터를 갖지 못하게 되면, 세컨더리 오피 로그에서 가장 최근의 타임스탬프를 이용해서 업데이트 되지 못한 복제를 모니터할 수 있다.  

  

**예) 레플리카 세트 내의 프라이머리 노드에 쓰기를 수행하는 경우의 작업**  

- 쓰기가 기록된다. 그리고 프라이머리 노드의 오피로그에 추가된다.
- 이후 모든 세컨더리 노드도 자신의 오피로그에 프라이머리 노드의 오피로그를 복제한다.
- 해당 세컨더리 노드가 업데이트할 준비가 되었을 때 아래의 세가지 작업을 수행한다.
  - 1) 세컨더리는 자신의 오피로그에서 가장 최신의 타임스탬프에 해당하는 항목을 검사한다.
  - 2) 프라이머리 노드의 오피로그에서 1)에서 찾은 타임스탬프 이후의 모든 항목을 질의한다.
  - 3) 데이터 쓰기를 수행한다. 쓰기를 수행하는 이 항목들을 자신의 오피로그에 추가된다.
    - 저널링이 사용 가능한 환경에서 오피로그에 대한 쓰기 및 오피로그 적용은 트랜잭션 하나에서 이루어 진다. 그리고 이 트랜잭션은 원자적인 단위를 갖는다.



## 레플리카 세트의 장점

마스터 - 슬레이브 방식의 복제에 비해서 레플리카 세트를 사용했을 때의 장점이 더 많은 편이어서, 레플리카 세트 방식의 복제가 많이 사용되는 편이다.  

  

**자동 장애조치 보장**  

레플리카 세트는 프라이머리 노드, 세컨더리 노드, 아비터 노드를 가지고 있는데, 프라이머리 노드에 장애가 발생했을 때 선거를 통해서 어떤 노드를 프라이머리 노드로 변경할 지 선출하는 과정을 거친다. 

  

**정교한 구성 가능**  

마스터 슬레이브 방식에 비해 레플리카 세트는 복구하기가 간편하고, 더 정교하게 구성할 수 있다는 장점이 있다.  

  

## 레플리카 세트에서의 커밋과 롤백

원칙적으로는 프라이머리 노드에 하루 종일 쓰기 작업을 할 수 있다. 하지만, 이 쓰기 작업이 레플리카 셋의 구성원 들중 과반수의 노드에 복제되기 전에는 커밋되지 않은 것으로 간주된다.  

  

**롤백이 수행(발생)되는 경우**  

예를 들면 아래와 같은 경우 롤백이 발생한다.  

1) 프라이머리에 일련의 쓰기 연산을 수행했지만 프라이머리에 장애가 발생해, 세컨더리에 복제가 발생되지 않는 경우가 있다.  

- 프라이머리에 쓰는 데이터가 장애가 발생해서 세컨더리에 복제되지 않는 경우  

2) 그런데 갑자기 세컨더리가 프라이머리로 승격되었다.  

3) 새로운 프라이머리 노드에 대해 쓰기를 시작한다.  

4) 그런데, 이전의 프라이머리가 온라인 상태로 복구되었다.  

5) 이전의 프라이머리 노드는 이제는 세컨더리이므로 새로운 프라이머리 노드로부터 복제를 받으려 한다.  

6) 이때 이전의 프라이머리 노드가 새로운 프라이머리 노드의 오피 로그에는 존재하지 않는 쓰기 연산을 가지고 있다는 점이 문제가 된다.  

7) 이런 상황에서는 롤백이 발생한다.

  

롤백을 하게 되면 과반수의 노드에 복제된 적이 없는 쓰기 작업은 모두 취소된다. 이렇게 취소가 되면 아래와 같은 작업이 수행된다.

- 프라이머리 노드였던 세컨더리 오피로그에서 삭제
- 데이터파일의 컬렉션도 이전 상태로 되돌아가게 된다.

  

취소된 쓰기는 해당 노드의 데이터 경로에 rollback 이라는 서브 디렉터리에 저장된다. 롤백된 컬렉션에 대해 별도의 BSON 파일이 생성되는데, 이 파일 이름에는 롤백된 시간이 포함된다. 롤백된 도큐먼트를 복구해야 할 필요가 잇을 때 bsondump 유틸리티로 이 BSON 파일을 검사하고 mongorestore 를 사용해 복구할 수 있다.  

  

**롤백을 방지할 수 있는 방법들**  

애플리케이션에서 추가적인 쓰기 지연이 허용된다면, **쓰기 concern** 을 사용해서 각 쓰기 작업에 대해 데이터가 과반수의 노드에 복제되는 것을 확힐하게 할 수 있다. 쓰기 concern과 복제 지연 모니터링을 현명하게 이용하면 일반적인 롤백문제들을 감소시킬 수 있고, 피할수도 있다.

  

## 레플리카 세트에서의 하트비트,장애복구

레플리카 세트의 각 멤버는 디폴트 설정으로 다른 구성원들을 매 2초마다 한 번씩 핑(ping)을 한다. 이렇게 해서 시스템의 건강상태를 체크한다. 상태 명령을 실행해보면 상태에 대한 정보와 함께 마지막 하트비트의 타임스탬프를 확인할 수 있다.  

  

## 레플리카 세트에서의 프라이머리 구성원



## 레플리카 세트에서의 세컨더리 구성원



## 레플리카 세트에서의 아비터 구성원



## 레플리카 세트의 선거 방식

  

