# 카프카,주키퍼 설치 - 개발용 인스턴스 (1대 구성)

카프카 설치과정을 정리했다. 개발용 인스턴스이고, 비용의 문제가 있거나 단순 테스트 용도의 경우 1대로만 구성을 해야 할 때가 있다 이럴 경우에 대한 개발용 인스턴스로는 단일 인스턴스를 구성하는 것이 적절할 수 있다. 이렇게 단일 인스턴스를 구성하는 방식에 대해 정리해봤다.<br>

<br>

## 다운로드

```bash
$ wget https://dlcdn.apache.org/kafka/2.8.1/kafka_2.12-2.8.1.tgz

$ tar xvzf kafka_2.12-2.8.1.tgz

$ cd kafka_2.12-2.8.1/

$ ll
합계 40
-rw-r--r-- 1 ec2-user ec2-user 14520  9월 14 13:03 LICENSE
-rw-r--r-- 1 ec2-user ec2-user   953  9월 14 13:03 NOTICE
drwxr-xr-x 3 ec2-user ec2-user  4096  9월 14 13:06 bin
drwxr-xr-x 3 ec2-user ec2-user  4096  9월 14 13:06 config
drwxr-xr-x 2 ec2-user ec2-user  8192  9월 20 18:00 libs
drwxr-xr-x 2 ec2-user ec2-user   262  9월 14 13:06 licenses
drwxr-xr-x 2 ec2-user ec2-user    44  9월 14 13:06 site-docs

```

<br>

## 카프카 브로커 힙 메모리 설정

카프카 브로커를 실행시킬 때는 힙 메모리 설정을 해야 한다. 카프카 브로커는 레코드의 내용은 페이지 캐시로 시스템 메모리를 사용한다. 그리고 나머지 객체들은 힙 메모리에 저장해 사용한다. 이렇게 페이지 캐시를 주요하게 사용하고 나머지 객체들은 힙 메모리에 저장하기 때문에 실제 카프카 브로커 운영시 힙 메모리를 5GB 이상으로 설정하지 않는 편이다.<br>

카프카 다운로드시 기본으로 지정되어 있는 힙메모리 사이즈는 아래와 같다.

- 주키퍼 : 512MB
  - 참고) `bin/zookeeper-server-start.sh` 
  - `export KAFKA_HEAP_OPTS="-Xmx512M -Xms512M"`
- 카프카 : 1GB
  - 참고) `bin/kafka-server-start.sh` 
  - `export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"`

<br>

공부 용도로 `t2.micro` EC2 인스턴스에 카프카를 설치해 사용할 때는 아래와 같이 카프카 힙 메모리 사이즈를 400MB로 지정해주면, t2.micro 인스턴스의 기본 메모리 사양인 1GB를 넘어서지 않는다. (1G를 넘어서면 카프카 + 주키퍼 기본 메모리 사용량 1.5GB는 EC2 메모리 Limit 을 넘기기에 Cannot Allocate Memory 에러가 발생한다.)

- 카프카 : 1GB -> 400MB

```bash
$ vim ~/.bashrc

# ... 중략 ...

export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"

# ~/.bashrc 구동
$ source ~/.bashrc

# 환경변수 확인
$ echo $KAFKA_HEAP_OPTS
-Xmx400m -Xms400m
```

> .bashrc 파일은 bash 쉘이 실행될 때마다 반복적으로 구동되어 적용되는 파일이다.

<br>

## 카프카 브로커 실행 옵션 설정

이번 문서에서는 `advertised.listener` 만 설정예정.

- `advertised.listener`
  - 카프카 클라이언트, 커맨드 라인 툴을 브로커와 연결할 때 사용
  - 이번 예제에서는 테스트 용도로 사용할 것이기에  `advertised.listeners=PLAINTEXT://[아이피주소]:9092` 를 입력 



```bash
$ cd ~/env/kafka/kafka_2.12-2.8.1/config/
$ ls
connect-console-sink.properties    connect-file-source.properties   consumer.properties  server.properties
connect-console-source.properties  connect-log4j.properties         kraft                tools-log4j.properties
connect-distributed.properties     connect-mirror-maker.properties  log4j.properties     trogdor.conf
connect-file-sink.properties       connect-standalone.properties    producer.properties  zookeeper.properties


$ vim server.properties
# ...
advertised.listeners=PLAINTEXT://[퍼블릭 아이피주소]:9092
```

<br>

### config/server.properties 내의 기본 옵션들

- `broker.id=0` : 실행하는 카프카 브로커의 번호. 브로커들을 구분하기 위해 단 각 브로커들을 구분할 수 있는 중복되지 않는 번호를 지정해야 함.
- `listeners=PLAINTEXT://9092` : 카프카 브로커 통신에 사용할 IP,PORT. 따로 별도의 설정을 하지 않으면 모든 IP,PORT 에서 접속 가능
- `advertised.listeners=PLAINTEXT://[퍼블릭 아이피주소]:9092` : 카프카 클라이언트/카프카 커맨드라인툴에 접속할 때 사용하는 IP, PORT 정보
- `SASL_PLAINTEXT,SASL_SSL:SASL_SSL` : 보안 관련 프로토콜 매핑 설정
- `num.network.threads=3` : 네트워크 기능 사용시 네트워크 기능이 사용할 스레드 갯수 설정
- `num.io.threads=8` : 카프카 브로커 내부에서 사용할 스레드 갯수 지정
- `log.dirs=/tmp/kafka-logs` : 통신을 통해 가져온 데이터를 파일로 저장할 디렉터리 경로. 디렉터리는 미리 생성되어 있어야 오류가 발생하지 않는다. (브로커 실행 전에 해당 디렉터리 있는지 확인 필요)
- `num.partitions=1` : 파티션 갯수를 명시하지 않고 토픽을 생성할 때, 기본 파티션 갯수 설정. 파티션 갯수가 많아지면 병렬 처리 데이터 양이 늘어난다.
- `log.retention.hours=168` : 카프카 브로커가 저장한 파일이 보존되는 기간. 이 기간이 지나가면 삭제된다. 보통 `log.retention.hours` 보다는 `log.retention.ms` 값을 설정해 운영하는 것이 권장됨. `log.retention.ms=-1` 일 경우 파일은 영원히 삭제되지 않는다.
- `log.segment.bytes=1073741824`  카프카 브로커가 저장할 파일의 최대 크기. 이 크기를 넘어서면 새로운 파일이 생성됨.
- `log.retention.check.interval.ms=300000` : 카프카 브로커가 저장한 파일을 삭제하기 위해 체크하는 간격
- `zookeeper.connect=localhost:2181` : 카프카 브로커와 연결할 주키퍼의 IP,PORT 정보 (로컬호스트에 모두 다 때려넣을 예정이라 localhost:2181로 지정)
- `zookeeper.connection.timeout.ms=18000` : 주키퍼 커넥션 타임아웃 시간

<br>

## 주키퍼 실행

> 주키퍼를 상용환경에서 사용할 때는 3대 이상의 서버로 구성하고, 가장 권장되는 갯수는 5개이다. 트래픽이 적은 개발환경 레벨에서는 1개 수준으로 지정해 개발용도 VM 비용을 줄이는 것도 나쁜 것은 아니다. 1대만 실행하는 주키퍼는 'Quick-and-dirty single-node' 라고 부른다.

다운 받았던 카프카 바이너리 파일 내에는 주키퍼가 함께 있다. 주키퍼는 카프카 브로커에 대한 여러가지 메타정보들을 관리한다. 몽고DB를 예로 들면 샤드 클러스터 구성시 구성(Config) 서버와 같은 역할을 수행한다.<br>

주키퍼 실행시 `-daemon` 옵션을 주어 실행하고, 설정 파일의 위치로 `config/zookeeper.properties` 를 지정해서 주키퍼를 백그라운드로 실행시킬 수 있다. 주키퍼의 정상 실행여부 확인은 `jps` 명령어로 확인할 수 있다. <br>

주키퍼 실행을 실패할 경우 로그를 확인하고 싶을 때가 있는데, 간단하게 `-daemon` 옵션을 사용하지 않고 포어그라운드로 실행시켜서 로그를 확인해서 문제점을 확인할 수 있다.

<br>

- `jps` 
  - JVM 프로세스 상태를 보는 도구다. JVM 위에서 동작하는 프로세스를 확인할 수 있도록 해준다.
  - `-m` 옵션 : main 메서드에 전달된 인자를 확인할 수 있다.
  - `-v` 옵션 : JVM 에 전달된 인자(힙 메모리 설정, log4j 설정 등)를 함께 확인 가능

<br>

**주키퍼 실행 + vm 프로세스 확인**

```bash
$ cd ~/env/kafka/kafka_2.12-2.8.1/
$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties

# jvm 프로세스 확인
$ jps -vm
28995 Jps -vm -Dapplication.home=/home/ec2-user/env/java/java16 -Xms8m -Djdk.module.main=jdk.jcmd
11302 QuorumPeerMain config/zookeeper.properties -Xmx400m -Xms400m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/home/ec2-user/env/kafka/kafka_2.13-2.7.1/bin/../logs/zookeeper-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/home/ec2-user/env/kafka/kafka_2.13-2.7.1/bin/../logs -Dlog4j.configuration=file:bin/../config/log4j.properties
```

<br>

## 카프카 브로커 실행

`-daemon` 옵션을 주어서 `Kafka-server-start.sh` 파일을 구동시키자. `Kafka-server-start.sh` 파일은 `bin` 디렉터리에 있다.

```bash
$ bin/kafka-server-start.sh -daemon config/server.properties

$ jps -m
29136 Kafka config/server.properties
29605 Jps -m
11302 QuorumPeerMain config/zookeeper.properties

$ tail -f logs/server.log
[2021-09-20 20:24:06,574] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2021-09-20 20:24:06,667] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2021-09-20 20:24:06,675] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2021-09-20 20:24:06,684] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2021-09-20 20:24:06,684] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2021-09-20 20:24:06,694] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser)
[2021-09-20 20:24:06,694] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser)
[2021-09-20 20:24:06,694] INFO Kafka startTimeMs: 1632169446684 (org.apache.kafka.common.utils.AppInfoParser)
[2021-09-20 20:24:06,702] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2021-09-20 20:24:06,767] INFO [broker-0-to-controller-send-thread]: Recorded new controller, from now on will use broker 13.209.70.5:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
```

<br>

## 로컬컴퓨터에서 카프카와 통신

EC2 에 다운로드 받았던 파일을 똑같이 로컬PC에도 다운로드 받자.

```bash
$ mkdir ~/env/kafka
$ cd ~/env/kafka
$ wget https://dlcdn.apache.org/kafka/2.8.1/kafka_2.12-2.8.1.tgz
$ kafka_2.12-2.8.1.tgz
$ cd kafka_2.12-2.8.1
$ bin/kafka-broker-api-versions.sh --bootstrap-server [아이피주소]:9092

# 출력결과
[아이피주소]:9092 (id: 0 rack: null) -> (
	Produce(0): 0 to 9 [usable: 9],
	Fetch(1): 0 to 12 [usable: 12],
	ListOffsets(2): 0 to 6 [usable: 6],
	
	# ... 중략 ...
	
	UpdateFeatures(57): 0 [usable: 0],
	DescribeCluster(60): 0 [usable: 0],
	DescribeProducers(61): 0 [usable: 0]
)
```

카프카 브로커에 로컬 PC 에서 커맨드라인 툴로 명령을 내릴 경우 브로커의 버전과 CLI 툴의 버전을 맞추는 것이 권장되는 편이다. 카프카 브로커의 버전이 업그레이드 될때 커맨드 라인 툴의 세부적인 옵션이 다랄질수 있기에 명령이 실행되지 않을 경우도 있기 때문이다.<br>



### hosts 설정

AWS EC2 의 주소를 매번 직접 복사해서 넣기는 불편하다. 이럴 경우, 해당 주소에 대한 별칭을 `/etc/hosts` 에 입력해주면 지정해준 별칭으로 EC2에 접근/접속이 가능하다.

```bash
$ sudo vim /etc/hosts

# [아이피주소/퍼블릭DNS] [사용할 별칭]
[아이피주소] ec2-gosgjung-hotmail

```

<br>

카프카 호스트가 제대로 적용되었는지 확인해보기

```bash
$ bin/kafka-broker-api-versions.sh --bootstrap-server ec2-gosgjung-hotmail:9092

# 출력결과
[아이피주소]:9092 (id: 0 rack: null) -> (
	Produce(0): 0 to 9 [usable: 9],
	Fetch(1): 0 to 12 [usable: 12],
	ListOffsets(2): 0 to 6 [usable: 6],
	
	# ... 중략 ...
	
	UpdateFeatures(57): 0 [usable: 0],
	DescribeCluster(60): 0 [usable: 0],
	DescribeProducers(61): 0 [usable: 0]
)
```

















