# 카프카 기본 개념들 요약

실시간 트래픽을 경험하면서, 캐싱과 MQ만으로는 부족하다는 생각이 들었다. 메시징과 대기열기반 고빈도 대용량 INSERT 를 하나의 애플리케이션에서 서로 다른 작업으로 처리하고 있다. 지금까지 경험해본 바로는, 메시징에 있어서는 RabbitMQ 만큼 강력한 것은 없는 것 같다는 생각이 들었다. 하지만, 데이터 저장을 위한 대기열은 카프카가 적합하다는 생각이 들었다.<br>

그래서, 메시징 기능과 고빈도/대용량 배치 INSERT 기능을 애플리케이션 내부적으로는 분리는 했지만, 고빈도/대용량 배치 INSERT의 경우는 매커니즘을 조금은 다르게 하는 것이 어떨까 하는 생각을 했었다.<br>

매일 출퇴근 하면서 카프카 책을 자주 읽었고, 저번주 주말 밤샘 스터디 때 카프카 개념에 관련된 문서와, 프로듀서 컨슈머 예제를 모두 직접 스터디 했었다. 이때 알게된 것은 순서를 보장하는 메시징에 있어서는 RabbitMQ가 매우 좋다. 하지만, 대용량/고빈도 데이터 저장(=메시징이 아니다.)에 있어서는 카프카 역시도 고려 대상에 넣고 도전해 볼만 하겠다는 생각이 들었다. <br>

카프카는 여러개의 인스턴스에 분산해서 설치할 수도 있고, 하나의 서버에 통으로 설치하는 것 역시도 가능하다. 초기 개발단계에서 개발 적합성을 살펴보는 단계라면 단일 서버 내에서 통으로 설치해서 부하를 견디는지 테스트 해보는 것도 좋을 듯하다. <br>

현재 회사에서는 노드가 늘어나면 인프라 팀에서 싫어할 수도 있기에 분산으로 설치하기보다는 단일 노드로 설치해서 부족할 때마다 서버 스펙을 높이는 식으로 하기로 결정했다. 관리해주시는 분들 인력 자체도 없기에 이렇게 하는게 최선일 듯해보였다. 메시징기능 자체는 래빗 MQ로 분리해두었기에, 서버 인스턴스의 성능은 카프카와 함께 나눠 쓰면 부하를 어느정도 줄이는 것이 가능할 것 같다. 요즘 생각해보면 예전 회사가 일을 열심히 하기 위한 모든 환경이 잘 갖춰져 있었던 것 같다는 생각을 요즘 자주 한다.<br>

신기술(=카프카는 신기술은 아니지만, 보통사람들은 신기술이라고 인식)을 싫어하는 사람들이 보통은 대부분인 회사가 많다. 나 조차도 신기술은 일단 색안경을 쓰고 볼때가 있는지 반성할때가 많기는 하다. 그래서 이번에도 역시 hazelcast를 도입했던 때처럼 충분히 개인 시간에 공부를 해보고 예제 작성을 해보는 과정을 거쳤다. 실 트래픽 부하 테스트에 성공하면 카프카를 실시간 고빈도/대용량 Batch Insert 로직에 한정해서 프로듀서/컨슈머 기능으로 사용할 예정이다. 도저히 지금 가지고 있는 자원만으로 뭘 꾸려서 하는 것 자체가 진짜 고문이라는 생각이 들어서 몰래 카프카 관련해서 공부를 시작했었다. 카프카 기반의 데이터 저장 기능이 실트래픽 테스트에서 성공적이면 추후 개발 완료된 사항에 대해서 설명을 하는게 맞지 않을까 생각했다.<br>

예전 회사에서는 OOO 뮤직의 배포 시스템을 접했는데, DB와 운영 용도 VM을 제외하고 WAS 서버 인스턴스만 각각 단일 노드로 128개였고 이것들을 개별 노드들을 GUI에서 모두 확인 가능했고 관리도 가능했다. 개발팀 개발자 3명 정도로 모두 관리 가능했고, 이상이 생겼을때 인프라 문제라고 판단될 경우 인프라팀에 사내 게시판으로 문의했었는데, 서버 관리실 전원 플러그가 빠졌던 경험들 외에는 대부분의 경우 개발자 레벨에서 모두 처리 가능했었다. 요즘 들어 예전 회사 + 상위 계열사에 대한 향수가 모락모락 자주 피어났었다. 지금 회사에서는 서버 개발자 한명 한명이 이순신이 되어야 한다. (싫다는 이야기)<br>

이번 프로젝트가 성공하면, 데이터 로그 생성/분석 시스템과 이 로그를 시각화하는 시스템도 고려해볼 수 있지 않을까 하고 생각했다. 특정 데이터가 몇시 몇분에 나왔는지, 어떤 필드는 몇분에 한번씩 나오는지, 누락이 심한 필드는 뭔지 등을 그래프로 볼수 있는 시스템을 이것 저것 스터디 하다보면, 프론트 엔드 작업 없이 구축할수 있지 않을까 하는 생각을 했다. <br>

<br>

## 주키퍼

아파치 카프카는 주키퍼를 사용한다. 주로 컨슈머 클라이언트, 카프카 클러스터에 관련된 메타데이터(환경설정 정보)를 저장하기 위해 주키퍼를 사용한다.<br>

주키퍼가 주로 수행하는 역할은 아래와 같다.<br>

- 카프카 브로커, 토픽에 관련된 메타데이터 관리
- 컨슈머에 관련된 메타데이터들 관리
- 파티션 오프셋 관리

글로 표현하는 것보다, 학습효과를 높이려면 역시 그림과 함께 보면 나중에 기억하기 쉬울 듯 하다. 그래서 그림을 직접 그려봤다. 아래 그림은 직접 그린 그림.<br>

![이미지](./img/ZOOKEEPER-KAFKA-1.png)





## 주키퍼 앙상블

> 이번 프로젝트 범위에서는 앙상블을 구성하지 않을 것 같다. 프로젝트 목적에도 부합하지 않고 프로젝트 범위에도 부합하지 않는다. 더 중요한 것은 1인 개발 체제에서는 도저히 시간 자체가 나지를 않는다. 추후 고도화 시에 앙상블과, 카프카 클러스터링을 도입하게 될 것 같다. 나중에 고도화 시에 적용할 수도 있기에 미리 정리해두었다.<br>

<br>

주키퍼는 주로 카프카 브로커, 토픽, 컨슈머 등에 관련된 메타데이터 들을 통합, 관리하는데에 사용된다. 주키퍼를 클러스터화 한 것을 **앙상블(ensemble)** 이라고 부른다. 그냥 클러스터링 했다고 하면 되지 앙상블이라는 말을 써서 괜한 상상을 하게 했나 하는 그런 불만이 새로 접하는 사람들에게 생길수도 있겠다하는 생각이 들기도 한다.<br>

몽고DB에 샤드 클러스터링을 적용해본 경험이 있는 사람들이라면 구성서버(Config Server)를 떠올리면 될 것 같다. 스프링 클라우드에서도 구성서버와 관련된 개념을 제공하고 있다. 이런 기능들을 보면 대부분의 인프라들이 클라우드를 지원하려 노력하는 중이라는 것을 느끼게 되는 것 같다.<br>

하나의 주키퍼 앙상블은 여러 개의 서버(노드)를 멤버로 가질 수 있다. 이렇게 구성된 여러개의 서버에서 하나의 서버에만 서비스가 집중되지 않도록 주키퍼는 요청을 분산시킨다. 그리고 한 서버에서 처리한 결과를 다른 서버와 동기화(=복제)해서 데이터의 안전성을 보장한다.<br>

만약 클라이언트와 현재 연결된 서버중 하나가 문제가 생기면 대기중인 주키퍼 서버 중에서 하나를 자동 선정해서 새로 선택된 서버가 해당 서비스를 이어받아 처리한다.<br>

앙상블은 홀수개의 서버(3,5,...)를 멤버로 갖는다. 앙상블의 서버 중 과반수가 작동 가능하면 언제든 요청 처리가 가능하기 때문이다. 데이터 쓰기를 하는 서버를 리더(leader)라고 부르고, 나머지 대기 서버는 팔로어(follower)라고 부른다.<br>

<br>

> 주키퍼 앙상플은 다섯 개의 서버 노드를 갖도록 구성하는 것이 좋은 선택이다. 그리고 서버가 너무 많으면 오히려 성능이 저하될 수 있어서 노드를  다섯개보다 많게 구성하는 것은 바람직하지 않다.<br>

<br>



## 분산 커밋 로그, 분산 스트리밍 플랫폼



## 메시지, 배치

**메시지**<br>

카프카에서는 데이터의 기본 단위를 메시지(message)라고 부른다. 데이터베이스의 row(행) 또는 record(레코드)에 비유된다.<br>

카프카는 메시지를 바이트 배열의 데이터로 간주하고 특정 형식/의미는 없다.<br>

 메시지에는 '키(key)' 라는 개념의 메타 데이터가 포함될 수 있다. (키 역시도 바이트 배열이고 특별한 의미를 갖지 않는다.)<br>

메시지는 토픽으로 분류된 파티션에 수록(저장)된다. 이때 수록할 파티션을 결정할 때 일관된 해시 값으로 키를 생성한다. 해시는 항상 고유한 값을 생성하는 것을 보장하기에, 항상 같은 킷값으로는 항상 같은 파티션에 수록된다.<br>

**배치**<br>

카프카는 효율성을 위해 여러 개의 메시지를 모아 배치(batch) 형태로 파티션에 수록한다. 따라서 네트워크로부터 매번 각 메시지를 받아서 처리하는 데에 따른 부담을 줄일 수 있다.<br>

이때 대기시간(latency), 처리량(throughput) 간의 트레이드오프가 생길 수 있다. 배치의 크기가 크면 클수록 단위 시간당 처리될 수 있는 메시지는 많아지지만, 각 메시지의 전송 시간은 더 길어진다.<br>

배치에는 데이터 압축이 적용되기 때문에 효율적인 데이터 전송과 저장 능력을 제공한다.<br>

<br>

## 스키마

카프카는 메시지를 단순히 바이트 배열로 처리하지만, 내용을 이해하기 쉽도록 메시지의 구조를 나타내는 **스키마(schema)**를 사용할 수 있다.<br>

가장 간단한 방법으로는 JSON,XML 방식이 있다. 하지만, 강력한 데이터 타입에 대한 지원이 부족하고 스키마 버전 간의 호환성이 떨어진다. 이런 이유로 많은 개발자들이 Avro 를 선호한다. <br>

**Avro**<br>

Avro 는 하둡을 위해 개발된 직렬화(serialization) 프레임워크다. Avro 는 데이터를 직렬화하는 형식을 제공하며,메시지와는 별도로 스키마를 별도로 유지 관리한다. 다라서 스키마가 변경되더라도 애플리케이션의 코드를 추가하거나 변경할 필요가 없다. 또한 강력한 데이터 타입을 지원하고, 스키마 신구버전 간의 호환성도 제공한다.<br>

<br>

**스키마와 직렬화**<br>









